{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learned_index_convergence.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwQdmLVo1UQa",
        "colab_type": "code",
        "outputId": "fe07e9f7-9614-4e06-c600-299b33cfb96e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1666
        }
      },
      "source": [
        "import time\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import torch\n",
        "import torch.autograd\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from bisect import bisect_left\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#Functions for dataset Generation\n",
        "#################################\n",
        "\n",
        "def generate_dataset(N):\n",
        "    dataset = [exponential() for _ in range(N)]\n",
        "    #dataset = [lognormal() for _ in range(N)]\n",
        "    #dataset = [laplace() for _ in range(N)]\n",
        "    #dataset = [uniform() for _ in range(N)]\n",
        "    #dataset = [gaussian() for _ in range(N)]\n",
        "    dataset = sorted(dataset)\n",
        "    def KVrand():\n",
        "        x = random.choice(dataset)\n",
        "        y = dataset.index(x)\n",
        "        return x, y\n",
        "    return dataset, KVrand\n",
        "\n",
        "def exponential(lambda1=1.0):\n",
        "    u = random.random()\n",
        "    x = - math.log(u) / lambda1\n",
        "    return x \n",
        "\n",
        "def lognormal(mu=0, sigma=5.0):\n",
        "    x = random.lognormvariate(mu, sigma)\n",
        "    return x\n",
        "  \n",
        "def uniform(a=0.0,b=10.0):\n",
        "    x = random.uniform(a,b)\n",
        "    return x\n",
        "\n",
        "def gaussian(mu=0, sigma=5.0):\n",
        "    x = random.gauss(mu, sigma)\n",
        "    return x\n",
        "\n",
        "def laplace():\n",
        "    u = random.random()\n",
        "    if(u<=0.5):\n",
        "        x = math.log(2*u)\n",
        "    else:\n",
        "        x = -math.log(2-2*u)    \n",
        "    return x\n",
        "\n",
        "\n",
        "#Functions for Neural Network Configuration\n",
        "###########################################\n",
        "\n",
        "def create_NN(dim=128):\n",
        "    NN = torch.nn.Sequential(torch.nn.Linear(1, dim),torch.nn.ReLU(),torch.nn.Linear(dim, 1),)\n",
        "    return NN\n",
        "\n",
        "\n",
        "def to_tensor(x):   \n",
        "    return torch.unsqueeze(Variable(torch.Tensor(x)), 1)\n",
        "\n",
        "\n",
        "#Traditional Search Functions\n",
        "#############################\n",
        "\n",
        "def linear_search(x, dataset):\n",
        "    for idx, n in enumerate(dataset):\n",
        "        if n > x:\n",
        "            break\n",
        "    return idx - 1\n",
        "\n",
        "\n",
        "def binary_search(x, dataset):\n",
        "    i = bisect_left(dataset, x)\n",
        "    if i:\n",
        "        return i - 1\n",
        "    raise ValueError\n",
        "\n",
        "#Main\n",
        "#####\n",
        "\n",
        "def main():\n",
        "    N = 1000\n",
        "    lr = 0.0001\n",
        "    batch_no = 0\n",
        "    LF_x = []\n",
        "    LF_y = []  \n",
        "    minloss = N\n",
        "    \n",
        "    \n",
        "    dataset, KVrand = generate_dataset(N)\n",
        "    NN = create_NN()\n",
        "    optimizer = torch.optim.Adam(NN.parameters(), lr=lr)\n",
        "    \n",
        "#Training\n",
        "#########\n",
        "\n",
        "    start = time.time()\n",
        "    try:\n",
        "        while True:\n",
        "            batch_no = batch_no + 1\n",
        "            batch_x = []; batch_y = []\n",
        "            for _ in range(256):\n",
        "                x, y = KVrand()\n",
        "                batch_x.append(x)\n",
        "                batch_y.append(y)\n",
        "\n",
        "            batch_x = to_tensor(batch_x)\n",
        "            batch_y = to_tensor(batch_y)\n",
        "\n",
        "            Predicted_idx = NN(batch_x) * N\n",
        "\n",
        "            output = F.smooth_l1_loss(Predicted_idx, batch_y)\n",
        "            loss = output.data\n",
        "                      \n",
        "            if (minloss>loss.item()):\n",
        "               minloss=loss.item()\n",
        "               print('Minloss =',minloss,'at',time.time())\n",
        "\n",
        "            #print(loss, minloss,'at',time.time())  \n",
        "            \n",
        "            LF_x.append(batch_no)\n",
        "            LF_y.append(loss)\n",
        "            \n",
        "            if (loss.item()<1.0):\n",
        "                break\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            output.backward()\n",
        "            optimizer.step()\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "    end = time.time()\n",
        "    TrainingTime = end - start\n",
        "    print('Time required for Training =', TrainingTime)\n",
        "\n",
        "#Convergence Plot\n",
        "#################\n",
        "    plt.plot(LF_x, LF_y, 'b', label='Learned Index Structure')\n",
        "    plt.xlabel('Number of Batches')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Learning Convergence')\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    #import pdb\n",
        "    #pdb.set_trace()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minloss = 516.3041381835938 at 1552561163.5412402\n",
            "Minloss = 503.1219482421875 at 1552561163.545436\n",
            "Minloss = 468.69677734375 at 1552561163.5524855\n",
            "Minloss = 466.441650390625 at 1552561163.5690515\n",
            "Minloss = 440.1553955078125 at 1552561163.5853813\n",
            "Minloss = 426.336181640625 at 1552561163.6020646\n",
            "Minloss = 419.918212890625 at 1552561163.6081598\n",
            "Minloss = 390.0388488769531 at 1552561163.614062\n",
            "Minloss = 386.1229248046875 at 1552561163.6203244\n",
            "Minloss = 384.57281494140625 at 1552561163.6394212\n",
            "Minloss = 384.49053955078125 at 1552561163.6429129\n",
            "Minloss = 369.75128173828125 at 1552561163.6495514\n",
            "Minloss = 369.7259826660156 at 1552561163.653085\n",
            "Minloss = 336.18115234375 at 1552561163.6564503\n",
            "Minloss = 334.3038024902344 at 1552561163.6728754\n",
            "Minloss = 300.8546447753906 at 1552561163.6842046\n",
            "Minloss = 293.1239929199219 at 1552561163.7007108\n",
            "Minloss = 291.32415771484375 at 1552561163.7093334\n",
            "Minloss = 286.3512268066406 at 1552561163.7129045\n",
            "Minloss = 276.8747253417969 at 1552561163.716218\n",
            "Minloss = 268.2743225097656 at 1552561163.722583\n",
            "Minloss = 266.94073486328125 at 1552561163.731787\n",
            "Minloss = 253.333251953125 at 1552561163.7352436\n",
            "Minloss = 249.18624877929688 at 1552561163.744731\n",
            "Minloss = 246.27005004882812 at 1552561163.7566984\n",
            "Minloss = 244.47927856445312 at 1552561163.7601833\n",
            "Minloss = 242.98683166503906 at 1552561163.7662826\n",
            "Minloss = 238.95831298828125 at 1552561163.7697005\n",
            "Minloss = 225.79345703125 at 1552561163.776249\n",
            "Minloss = 220.72579956054688 at 1552561163.7826731\n",
            "Minloss = 217.70230102539062 at 1552561163.7888763\n",
            "Minloss = 211.47206115722656 at 1552561163.799938\n",
            "Minloss = 201.1583251953125 at 1552561163.805908\n",
            "Minloss = 186.6464080810547 at 1552561163.8121142\n",
            "Minloss = 181.1944580078125 at 1552561163.8315973\n",
            "Minloss = 180.93328857421875 at 1552561163.845685\n",
            "Minloss = 160.7238311767578 at 1552561163.8518457\n",
            "Minloss = 149.18447875976562 at 1552561163.8789165\n",
            "Minloss = 144.31385803222656 at 1552561163.8959122\n",
            "Minloss = 137.25335693359375 at 1552561163.9129112\n",
            "Minloss = 128.32012939453125 at 1552561163.935666\n",
            "Minloss = 124.09278869628906 at 1552561163.9470294\n",
            "Minloss = 122.3805160522461 at 1552561163.9626677\n",
            "Minloss = 121.5484848022461 at 1552561163.9663265\n",
            "Minloss = 116.44587707519531 at 1552561163.9799712\n",
            "Minloss = 115.60111236572266 at 1552561163.9911704\n",
            "Minloss = 110.67489624023438 at 1552561164.0000927\n",
            "Minloss = 106.6255874633789 at 1552561164.024647\n",
            "Minloss = 102.55211639404297 at 1552561164.0334756\n",
            "Minloss = 100.82929992675781 at 1552561164.0534892\n",
            "Minloss = 100.5551528930664 at 1552561164.0596883\n",
            "Minloss = 99.55619049072266 at 1552561164.068692\n",
            "Minloss = 94.98323059082031 at 1552561164.082836\n",
            "Minloss = 90.14895629882812 at 1552561164.1107595\n",
            "Minloss = 87.61101531982422 at 1552561164.1226132\n",
            "Minloss = 82.55766296386719 at 1552561164.1901822\n",
            "Minloss = 81.5678482055664 at 1552561164.2095535\n",
            "Minloss = 69.95285034179688 at 1552561164.236894\n",
            "Minloss = 66.79142761230469 at 1552561164.3189194\n",
            "Minloss = 63.19296646118164 at 1552561164.338518\n",
            "Minloss = 62.2958869934082 at 1552561164.3686664\n",
            "Minloss = 60.899600982666016 at 1552561164.3721836\n",
            "Minloss = 57.78447723388672 at 1552561164.3985808\n",
            "Minloss = 56.36394119262695 at 1552561164.4267206\n",
            "Minloss = 54.07929992675781 at 1552561164.4491253\n",
            "Minloss = 49.85743713378906 at 1552561164.4681864\n",
            "Minloss = 47.93182373046875 at 1552561164.501409\n",
            "Minloss = 47.225364685058594 at 1552561164.5233672\n",
            "Minloss = 41.80247116088867 at 1552561164.5269015\n",
            "Minloss = 41.15998840332031 at 1552561164.579019\n",
            "Minloss = 37.808631896972656 at 1552561164.593988\n",
            "Minloss = 34.86427688598633 at 1552561164.6092205\n",
            "Minloss = 33.49467086791992 at 1552561164.6426342\n",
            "Minloss = 19.357879638671875 at 1552561164.683189\n",
            "Minloss = 17.6932430267334 at 1552561164.8251793\n",
            "Minloss = 17.48007583618164 at 1552561164.9045749\n",
            "Minloss = 16.22343635559082 at 1552561164.9264655\n",
            "Minloss = 12.993610382080078 at 1552561164.982317\n",
            "Minloss = 11.638339042663574 at 1552561165.107642\n",
            "Minloss = 10.862565994262695 at 1552561165.1769006\n",
            "Minloss = 10.377422332763672 at 1552561165.2198977\n",
            "Minloss = 9.973963737487793 at 1552561165.3076954\n",
            "Minloss = 8.999732971191406 at 1552561165.4240427\n",
            "Minloss = 8.933582305908203 at 1552561165.5103862\n",
            "Minloss = 8.354663848876953 at 1552561165.546459\n",
            "Minloss = 8.319246292114258 at 1552561165.5558622\n",
            "Minloss = 7.2487568855285645 at 1552561165.5750625\n",
            "Minloss = 6.7485246658325195 at 1552561165.635589\n",
            "Minloss = 5.7518086433410645 at 1552561165.7063544\n",
            "Minloss = 5.685975074768066 at 1552561165.9750595\n",
            "Minloss = 5.31151008605957 at 1552561165.978729\n",
            "Minloss = 4.0288238525390625 at 1552561166.0448096\n",
            "Minloss = 3.96639347076416 at 1552561166.1932762\n",
            "Minloss = 3.640150308609009 at 1552561166.2835903\n",
            "Minloss = 3.4794387817382812 at 1552561166.490399\n",
            "Minloss = 3.469522476196289 at 1552561166.587744\n",
            "Minloss = 2.9169180393218994 at 1552561166.5965788\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}